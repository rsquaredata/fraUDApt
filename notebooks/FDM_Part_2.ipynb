{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LdLCzV-5Eyr",
        "outputId": "0b1964c7-b1d5-48d7-abdc-371d630d5cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargé : kaggle_source_cate_0_test.npy | Forme : (13686, 51)\n",
            "Chargé : kaggle_source_cate_0_test_label.npy | Forme : (13686, 2)\n",
            "Chargé : kaggle_source_cate_0_train.npy | Forme : (41058, 51)\n",
            "Chargé : kaggle_source_cate_0_train_label.npy | Forme : (41058, 2)\n"
          ]
        }
      ],
      "source": [
        "#Chargement des datasets source\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "\n",
        "base_url = \"https://raw.githubusercontent.com/lmuxz/SCDA/master/data/\"\n",
        "suffixes = [\"test\", \"test_label\", \"train\", \"train_label\"]\n",
        "\n",
        "# Dictionnaire pour stocker vos matrices numpy\n",
        "data_store_source = {}\n",
        "\n",
        "\n",
        "for suffix in suffixes:\n",
        "    file_name = f\"kaggle_source_cate_0_{suffix}.npy\"\n",
        "    url = f\"{base_url}{file_name}\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # numpy.load nécessite un objet \"file-like\", d'où l'utilisation de BytesIO\n",
        "        data_store_source[file_name] = np.load(io.BytesIO(response.content))\n",
        "        print(f\"Chargé : {file_name} | Forme : {data_store_source[file_name].shape}\")\n",
        "    else:\n",
        "        print(f\"Échec pour {file_name} (Code : {response.status_code})\")\n",
        "\n",
        "# Exemple d'accès :\n",
        "# train_data_0 = data_store['kaggle_source_cate_0_train.npy']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passage en dataframe pandas des datasets source :\n",
        "import pandas as pd\n",
        "\n",
        "def create_dataframes(data_dict):\n",
        "# 1. Extraction des matrices\n",
        "    x_train = data_dict['kaggle_source_cate_0_train.npy']\n",
        "    y_train = data_dict['kaggle_source_cate_0_train_label.npy']\n",
        "\n",
        "    x_test = data_dict['kaggle_source_cate_0_test.npy']\n",
        "    y_test = data_dict['kaggle_source_cate_0_test_label.npy']\n",
        "\n",
        "    # 2. Conversion des features en DataFrames\n",
        "    # On s'assure que les colonnes de features ont des noms clairs (ex: feat_0, feat_1...)\n",
        "    train_df = pd.DataFrame(x_train).add_prefix('feat_')\n",
        "    test_df = pd.DataFrame(x_test).add_prefix('feat_')\n",
        "\n",
        "    # 3. Conversion et intégration des labels (2 colonnes)\n",
        "    # On crée un DataFrame temporaire pour les labels avec des noms explicites\n",
        "    y_train_df = pd.DataFrame(y_train, columns=['label_0', 'label_1'], index=train_df.index)\n",
        "    y_test_df = pd.DataFrame(y_test, columns=['label_0', 'label_1'], index=test_df.index)\n",
        "\n",
        "    # 4. Concaténation horizontale (colonnes de features + colonnes de labels)\n",
        "    train_final = pd.concat([train_df, y_train_df], axis=1)\n",
        "    test_final = pd.concat([test_df, y_test_df], axis=1)\n",
        "\n",
        "    return train_final, test_final\n",
        "\n",
        "# Exécution\n",
        "train_df, test_df = create_dataframes(data_store_source)\n",
        "\n",
        "# Vérification de la structure\n",
        "print(f\"Colonnes disponibles : {list(train_df.columns)}\")\n",
        "print(f\"Forme finale Train : {train_df.shape}\") # Devrait être (n, features + 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5VenjRzBg2J",
        "outputId": "463c1d95-bf55-44eb-9384-978ddf351194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colonnes disponibles : ['feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_7', 'feat_8', 'feat_9', 'feat_10', 'feat_11', 'feat_12', 'feat_13', 'feat_14', 'feat_15', 'feat_16', 'feat_17', 'feat_18', 'feat_19', 'feat_20', 'feat_21', 'feat_22', 'feat_23', 'feat_24', 'feat_25', 'feat_26', 'feat_27', 'feat_28', 'feat_29', 'feat_30', 'feat_31', 'feat_32', 'feat_33', 'feat_34', 'feat_35', 'feat_36', 'feat_37', 'feat_38', 'feat_39', 'feat_40', 'feat_41', 'feat_42', 'feat_43', 'feat_44', 'feat_45', 'feat_46', 'feat_47', 'feat_48', 'feat_49', 'feat_50', 'label_0', 'label_1']\n",
            "Forme finale Train : (41058, 53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_source = train_df.drop(columns=['label_0', 'label_1'])\n",
        "y_train_source= train_df['label_1']\n",
        "\n",
        "X_test_source = test_df.drop(columns=['label_0', 'label_1'])\n",
        "y_test_source = test_df['label_1']"
      ],
      "metadata": {
        "id": "oJ1b7xQTjY2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Chargement des datasets cible\n",
        "\n",
        "base_url = \"https://raw.githubusercontent.com/lmuxz/SCDA/master/data/\"\n",
        "suffixes = [\"test\", \"test_label\", \"train\"]\n",
        "\n",
        "# Dictionnaire pour stocker vos matrices numpy\n",
        "data_store_target = {}\n",
        "\n",
        "for i in range(4):\n",
        "    for suffix in suffixes:\n",
        "        file_name = f\"kaggle_target_cate_{i}_{suffix}.npy\"\n",
        "        url = f\"{base_url}{file_name}\"\n",
        "\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            # numpy.load nécessite un objet \"file-like\", d'où l'utilisation de BytesIO\n",
        "            data_store_target[file_name] = np.load(io.BytesIO(response.content))\n",
        "            print(f\"Chargé : {file_name} | Forme : {data_store_target[file_name].shape}\")\n",
        "        else:\n",
        "            print(f\"Échec pour {file_name} (Code : {response.status_code})\")\n",
        "\n",
        "# Exemple d'accès :\n",
        "# train_data_0 = data_store['kaggle_source_cate_0_train.npy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dddo9d64-gLg",
        "outputId": "3ab162be-f98c-4135-f3cd-6d9c3c59a9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargé : kaggle_target_cate_0_test.npy | Forme : (20930, 51)\n",
            "Chargé : kaggle_target_cate_0_test_label.npy | Forme : (20930, 2)\n",
            "Chargé : kaggle_target_cate_0_train.npy | Forme : (62788, 51)\n",
            "Chargé : kaggle_target_cate_1_test.npy | Forme : (20930, 51)\n",
            "Chargé : kaggle_target_cate_1_test_label.npy | Forme : (20930, 2)\n",
            "Chargé : kaggle_target_cate_1_train.npy | Forme : (62788, 51)\n",
            "Chargé : kaggle_target_cate_2_test.npy | Forme : (20929, 51)\n",
            "Chargé : kaggle_target_cate_2_test_label.npy | Forme : (20929, 2)\n",
            "Chargé : kaggle_target_cate_2_train.npy | Forme : (62789, 51)\n",
            "Chargé : kaggle_target_cate_3_test.npy | Forme : (20929, 51)\n",
            "Chargé : kaggle_target_cate_3_test_label.npy | Forme : (20929, 2)\n",
            "Chargé : kaggle_target_cate_3_train.npy | Forme : (62789, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Passage en dataframe pandas des datasets cible :\n",
        "all_train_target_dfs = []\n",
        "all_test_target_dfs = []\n",
        "datasets_target_par_index = {}\n",
        "\n",
        "for i in range(4):\n",
        "    print(f\"Traitement de l'index {i}...\")\n",
        "\n",
        "    # 1. Récupération\n",
        "    X_train_raw = data_store_target[f'kaggle_target_cate_{i}_train.npy']\n",
        "    X_test_raw  = data_store_target[f'kaggle_target_cate_{i}_test.npy']\n",
        "    y_test_raw  = data_store_target[f'kaggle_target_cate_{i}_test_label.npy']\n",
        "\n",
        "    # 2. Conversion dynamique\n",
        "    df_X_train = pd.DataFrame(X_train_raw).add_prefix('feat_')\n",
        "    df_X_test  = pd.DataFrame(X_test_raw).add_prefix('feat_')\n",
        "\n",
        "    # On crée les noms de colonnes dynamiquement pour les labels (label_0, label_1, etc.)\n",
        "    col_labels = [f'label_{j}' for j in range(y_test_raw.shape[1])]\n",
        "    df_y_test  = pd.DataFrame(y_test_raw, columns=col_labels)\n",
        "\n",
        "    # 3. Concaténation horizontale\n",
        "    df_train_full = df_X_train\n",
        "    df_test_full  = pd.concat([df_X_test, df_y_test], axis=1)\n",
        "\n",
        "    # Identification de la source\n",
        "    df_train_full['source_index'] = i\n",
        "    df_test_full['source_index'] = i\n",
        "\n",
        "    datasets_target_par_index[i] = {'train': df_train_full, 'test': df_test_full}\n",
        "    all_train_target_dfs.append(df_train_full)\n",
        "    all_test_target_dfs.append(df_test_full)\n",
        "\n",
        "# 4. Fusion finale\n",
        "df_final_train_target = pd.concat(all_train_target_dfs, ignore_index=True)\n",
        "df_final_test_target  = pd.concat(all_test_target_dfs, ignore_index=True)\n",
        "\n",
        "print(f\"\\nTerminé ! Colonnes créées pour les labels : {col_labels}\")\n",
        "print(f\"Format final du train : {df_final_train_target.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ZPYnGeDHPy",
        "outputId": "aef0fe27-1976-4271-c1ad-19dc7360d809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traitement de l'index 0...\n",
            "Traitement de l'index 1...\n",
            "Traitement de l'index 2...\n",
            "Traitement de l'index 3...\n",
            "\n",
            "Terminé ! Colonnes créées pour les labels : ['label_0', 'label_1']\n",
            "Format final du train : (251154, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_target = df_final_train_target.drop(columns=['source_index'])\n",
        "X_test_target = df_final_test_target.drop(columns=['label_0', 'label_1', 'source_index'])\n",
        "y_test_target = df_final_test_target['label_1']"
      ],
      "metadata": {
        "id": "rOpQ2pJaj5pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_train_target.head)"
      ],
      "metadata": {
        "id": "rkoZa7DbFK3l",
        "outputId": "78a9cd96-04a4-4f72-d1f3-e029cd94bdfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of         feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
            "0          0.0    44.0     0.0   243.0    10.0     2.0    28.0     1.0   \n",
            "1          0.0    44.0     1.0   437.0    39.0     4.0    96.0     2.0   \n",
            "2          0.0    44.0     0.0   450.0    10.0     4.0    96.0     1.0   \n",
            "3          1.0    44.0     0.0   427.0    65.0     4.0    32.0     2.0   \n",
            "4          1.0    44.0     0.0   161.0    65.0     2.0    94.0     1.0   \n",
            "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "251149     1.0    56.0     0.0   100.0    65.0     4.0    32.0     2.0   \n",
            "251150     0.0    53.0     0.0   385.0    65.0     2.0    94.0     1.0   \n",
            "251151     0.0    53.0     0.0   298.0    65.0     2.0    94.0     2.0   \n",
            "251152     1.0    44.0     0.0   464.0    39.0     4.0    96.0     1.0   \n",
            "251153     0.0    83.0     0.0   298.0    65.0     2.0    94.0     2.0   \n",
            "\n",
            "          feat_8    feat_9  ...   feat_42   feat_43   feat_44   feat_45  \\\n",
            "0       0.693147  0.000000  ...  0.000000  5.119283  5.119283  3.491687   \n",
            "1       0.693147  0.693147  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "2       0.693147  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "3       0.693147  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "4       0.693147  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "...          ...       ...  ...       ...       ...       ...       ...   \n",
            "251149  0.693147  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "251150  0.693147  0.000000  ...  2.397895  6.513064  6.513064  0.000000   \n",
            "251151  0.693147  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "251152  0.693147  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "251153  0.693147  0.000000  ...  0.693147  4.086178  4.086178  0.000000   \n",
            "\n",
            "         feat_46   feat_47   feat_48   feat_49   feat_50  source_index  \n",
            "0       4.514456  4.514456  4.514456  4.514456  0.000000             0  \n",
            "1       0.000000  0.000000  0.000000  0.000000  0.000000             0  \n",
            "2       0.000000  0.000000  0.000000  0.000000  0.000000             0  \n",
            "3       0.000000  0.000000  0.000000  0.000000  0.000000             0  \n",
            "4       0.000000  0.000000  0.000000  0.000000  0.000000             0  \n",
            "...          ...       ...       ...       ...       ...           ...  \n",
            "251149  0.000000  0.000000  0.000000  0.000000  0.000000             3  \n",
            "251150  4.486026  4.486026  4.486026  4.486026  6.373525             3  \n",
            "251151  0.000000  0.000000  0.000000  0.000000  0.000000             3  \n",
            "251152  0.000000  0.000000  0.000000  0.000000  0.000000             3  \n",
            "251153  0.000000  0.000000  0.000000  0.000000  4.086178             3  \n",
            "\n",
            "[251154 rows x 52 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Procédure UDA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def perform_domain_adaptation(X_source, y_source, X_target,X_eval, y_target_oracle):\n",
        "    \"\"\"\n",
        "    Implémente l'adaptation de domaine par re-pondération d'importance\n",
        "    et correction locale k-NN.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Calcul des poids d'importance via Classifieur de Domaine ---\n",
        "    # On crée un dataset pour apprendre à distinguer Source (0) de Cible (1)\n",
        "    X_domain = np.vstack([X_source, X_target])\n",
        "    y_domain = np.hstack([np.zeros(len(X_source)), np.ones(len(X_target))])\n",
        "\n",
        "    domain_clf = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "    domain_clf.fit(X_domain, y_domain)\n",
        "\n",
        "    # Probabilité d'appartenir à la cible P(Target|x)\n",
        "    probs = domain_clf.predict_proba(X_source)[:, 1]\n",
        "\n",
        "    # Poids d'importance w(x) = P(Target|x) / P(Source|x)\n",
        "    # On ajoute un epsilon pour éviter la division par zéro\n",
        "    weights_global = probs / (1 - probs + 1e-6)\n",
        "\n",
        "    # --- 2. Affinement local par k-NN ---\n",
        "    # On cherche à voir si un point source est \"entouré\" de points cibles\n",
        "    knn_source = NearestNeighbors(n_neighbors=5).fit(X_source)\n",
        "    distances, indices = knn_source.kneighbors(X_target)\n",
        "\n",
        "    # On augmente le poids des points source qui sont les plus proches voisins de la cible\n",
        "    local_counts = np.zeros(len(X_source))\n",
        "    for idx_list in indices:\n",
        "        local_counts[idx_list] += 1\n",
        "\n",
        "    weights_local = local_counts / np.max(local_counts + 1e-6)\n",
        "\n",
        "    # --- 3. Combinaison des poids et Normalisation ---\n",
        "    # Fusion des approches globale (densité) et locale (voisinage)\n",
        "    final_weights = weights_global * (1 + weights_local)\n",
        "    final_weights = final_weights / np.mean(final_weights) # Normalisation\n",
        "\n",
        "    # --- 4. Entraînement du modèle XGBoost re-pondéré ---\n",
        "    # Note : On combine le class_weighting précédent avec les poids d'adaptation\n",
        "    # via le paramètre sample_weight de la méthode fit()\n",
        "\n",
        "    # Calcul du ratio pour le déséquilibre de classe (calculé sur Source)\n",
        "    ratio = np.bincount(y_source)[0] / np.bincount(y_source)[1]\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        learning_rate=0.1,\n",
        "        max_depth=9,\n",
        "        scale_pos_weight=ratio,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Entraînement sur Source avec les poids d'adaptation de domaine\n",
        "    model.fit(X_source, y_source, sample_weight=final_weights)\n",
        "\n",
        "    # --- 5. Évaluation \"Oracle\" sur le Domaine Cible ---\n",
        "    y_pred_target = model.predict(X_eval)\n",
        "\n",
        "    print(\"--- Rapport de Performance Oracle (Domaine Cible) ---\")\n",
        "    print(classification_report(y_target_oracle, y_pred_target))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Appel de la fonction (exemple théorique)\n",
        "# model_adapted = perform_domain_adaptation(X_src, y_src, X_tgt, y_tgt_oracle)"
      ],
      "metadata": {
        "id": "w3QQv4MzQ6rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_adapted = perform_domain_adaptation(X_source = X_train_source,\n",
        "    y_source = y_train_source,\n",
        "    X_target = X_train_target,\n",
        "    X_eval = X_test_target,\n",
        "    y_target_oracle = y_test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16OeBtS0lQcs",
        "outputId": "57ae7690-92a5-4263-8f73-ff3d484062cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Rapport de Performance Oracle (Domaine Cible) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96     78301\n",
            "           1       0.44      0.70      0.54      5417\n",
            "\n",
            "    accuracy                           0.92     83718\n",
            "   macro avg       0.71      0.82      0.75     83718\n",
            "weighted avg       0.94      0.92      0.93     83718\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "import scipy.linalg\n",
        "# --- Initialisation des listes pour le tableau ---\n",
        "noms_methodes = []\n",
        "recalls = []\n",
        "precisions = []\n",
        "f1_scores = []\n",
        "\n",
        "# --- Fonction utilitaire pour enregistrer les scores ---\n",
        "def evaluer_et_stocker(nom, y_pred, y_true):\n",
        "    noms_methodes.append(nom)\n",
        "    recalls.append(recall_score(y_true, y_pred))\n",
        "    precisions.append(precision_score(y_true, y_pred))\n",
        "    f1_scores.append(f1_score(y_true, y_pred))\n",
        "\n",
        "# ==========================================\n",
        "# 1. FONCTIONS D'ADAPTATION\n",
        "# ==========================================\n",
        "\n",
        "def compute_importance_weights(X_src, X_tgt):\n",
        "    \"\"\"Calcule les poids d'importance (Global + Local)\"\"\"\n",
        "    # Global\n",
        "    X_dom = np.vstack([X_src, X_tgt])\n",
        "    y_dom = np.hstack([np.zeros(len(X_src)), np.ones(len(X_tgt))])\n",
        "    clf = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42).fit(X_dom, y_dom)\n",
        "    probs = clf.predict_proba(X_src)[:, 1]\n",
        "    w_global = probs / (1 - probs + 1e-6)\n",
        "\n",
        "    # Local\n",
        "    knn = NearestNeighbors(n_neighbors=5).fit(X_src)\n",
        "    _, indices = knn.kneighbors(X_tgt)\n",
        "    counts = np.zeros(len(X_src))\n",
        "    for idx in indices: counts[idx] += 1\n",
        "    w_local = counts / (np.max(counts) + 1e-6)\n",
        "\n",
        "    final_w = w_global * (1 + w_local)\n",
        "    return final_w / np.mean(final_w)\n",
        "\n",
        "def coral_alignment(X_src, X_tgt):\n",
        "    \"\"\"Aligne la covariance de la source sur celle de la cible\"\"\"\n",
        "    # Centrage des données\n",
        "    X_src_c = X_src - np.mean(X_src, axis=0)\n",
        "    X_tgt_c = X_tgt - np.mean(X_tgt, axis=0)\n",
        "\n",
        "    # Calcul des matrices de covariance\n",
        "    cov_src = np.cov(X_src_c, rowvar=False) + np.eye(X_src.shape[1])\n",
        "    cov_tgt = np.cov(X_tgt_c, rowvar=False) + np.eye(X_tgt.shape[1])\n",
        "\n",
        "    # Transformation CORAL : X_src_new = X_src * cov_src^{-1/2} * cov_tgt^{1/2}\n",
        "    inv_sqrt_src = scipy.linalg.inv(scipy.linalg.sqrtm(cov_src))\n",
        "    sqrt_tgt = scipy.linalg.sqrtm(cov_tgt)\n",
        "\n",
        "    X_src_coral = np.real(X_src_c @ inv_sqrt_src @ sqrt_tgt)\n",
        "    return X_src_coral + np.mean(X_tgt, axis=0)\n",
        "\n",
        "# ==========================================\n",
        "# 2. PRÉPARATION\n",
        "# ==========================================\n",
        "\n",
        "# Conversion en arrays NumPy (si nécessaire)\n",
        "X_train_source_np = np.array(X_train_source) if isinstance(X_train_source, pd.DataFrame) else X_train_source\n",
        "X_train_target_np = np.array(X_train_target) if isinstance(X_train_target, pd.DataFrame) else X_train_target\n",
        "X_test_target_np = np.array(X_test_target) if isinstance(X_test_target, pd.DataFrame) else X_test_target\n",
        "\n",
        "# A. Calcul des composants UDA\n",
        "weights_uda = compute_importance_weights(X_train_source_np, X_train_target_np)\n",
        "X_train_source_coral = coral_alignment(X_train_source_np, X_train_target_np)\n",
        "\n",
        "# Paramètres XGBoost\n",
        "params = {\n",
        "    'learning_rate': 0.1, 'max_depth': 9, 'random_state': 42,\n",
        "    'scale_pos_weight': np.sum(y_train_source == 0) / np.sum(y_train_source == 1)\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# ENTRAÎNEMENT ET ÉVALUATION\n",
        "# ==========================================\n",
        "\n",
        "# 1. Baseline\n",
        "m0 = XGBClassifier(**params).fit(X_train_source_np, y_train_source)\n",
        "evaluer_et_stocker('Baseline', m0.predict(X_test_target_np), y_test_target)\n",
        "\n",
        "# 2. Re-weighting (Poids w(x))\n",
        "m1 = XGBClassifier(**params).fit(X_train_source_np, y_train_source, sample_weight=weights_uda)\n",
        "evaluer_et_stocker('UDA (Re-weighting)', m1.predict(X_test_target_np), y_test_target)\n",
        "\n",
        "# 3. CORAL (Alignement des features)\n",
        "m2 = XGBClassifier(**params).fit(X_train_source_coral, y_train_source)\n",
        "evaluer_et_stocker('UDA (CORAL)', m2.predict(X_test_target_np), y_test_target)\n",
        "\n",
        "# 4. Combinée\n",
        "m3 = XGBClassifier(**params).fit(X_train_source_coral, y_train_source, sample_weight=weights_uda)\n",
        "evaluer_et_stocker('UDA (Combinée)', m3.predict(X_test_target_np), y_test_target)\n",
        "# Pour CORAL, transformer aussi le test set\n",
        "X_test_target_coral = coral_alignment(X_test_target_np, X_train_target_np)\n",
        "\n",
        "# 3. CORAL (Alignement des features)\n",
        "m2 = XGBClassifier(**params).fit(X_train_source_coral, y_train_source)\n",
        "evaluer_et_stocker('UDA (CORAL)', m2.predict(X_test_target_coral), y_test_target)\n",
        "\n",
        "# 4. Combinée\n",
        "m3 = XGBClassifier(**params).fit(X_train_source_coral, y_train_source, sample_weight=weights_uda)\n",
        "evaluer_et_stocker('UDA (Combinée)', m3.predict(X_test_target_coral), y_test_target)\n",
        "\n",
        "# ==========================================\n",
        "# CRÉATION DU DATAFRAME (SÉCURISÉE)\n",
        "# ==========================================\n",
        "\n",
        "df_comp = pd.DataFrame({\n",
        "    'Méthode': noms_methodes,\n",
        "    'Recall': recalls,\n",
        "    'Précision': precisions,\n",
        "    'F1-Score': f1_scores\n",
        "})\n",
        "\n",
        "print(df_comp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr41NbhipRpe",
        "outputId": "53d9a91c-e08b-4f19-ecbc-f0a9e0fd46b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Méthode    Recall  Précision  F1-Score\n",
            "0            Baseline  0.718663   0.427708  0.536263\n",
            "1  UDA (Re-weighting)  0.696880   0.442919  0.541607\n",
            "2         UDA (CORAL)  0.623777   0.543772  0.581033\n",
            "3      UDA (Combinée)  0.594425   0.526919  0.558640\n",
            "4         UDA (CORAL)  0.623777   0.543772  0.581033\n",
            "5      UDA (Combinée)  0.594425   0.526919  0.558640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_comp.to_latex(index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "m02fEay10N2r",
        "outputId": "02276fb1-406e-4347-8b25-482922aec30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-7504277.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-7504277.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(df_comp.to_latex(index=False)\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    }
  ]
}