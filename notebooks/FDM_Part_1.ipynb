{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA-x-3-K4v4A",
        "outputId": "49ca4e0a-c5aa-42aa-8073-53c14c8e47e1"
      },
      "outputs": [],
      "source": [
        "#Chargement des datasets\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "\n",
        "base_url = \"https://raw.githubusercontent.com/lmuxz/SCDA/master/data/\"\n",
        "suffixes = [\"test\", \"test_label\", \"train\", \"train_label\"]\n",
        "\n",
        "# Dictionnaire pour stocker les matrices numpy\n",
        "data_store = {}\n",
        "\n",
        "for i in range(4):\n",
        "    for suffix in suffixes:\n",
        "        file_name = f\"kaggle_source_cate_{i}_{suffix}.npy\"\n",
        "        url = f\"{base_url}{file_name}\"\n",
        "\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            # numpy.load n√©cessite un objet \"file-like\", d'o√π l'utilisation de BytesIO\n",
        "            data_store[file_name] = np.load(io.BytesIO(response.content))\n",
        "            print(f\"Charg√© : {file_name} | Forme : {data_store[file_name].shape}\")\n",
        "        else:\n",
        "            print(f\"√âchec pour {file_name} (Code : {response.status_code})\")\n",
        "\n",
        "# Exemple d'acc√®s :\n",
        "# train_data_0 = data_store['kaggle_source_cate_0_train.npy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42oth4x_JZIq",
        "outputId": "ca24d901-b7c2-4072-d371-1b813333167f"
      },
      "outputs": [],
      "source": [
        "# Passage en dataframe pandas\n",
        "import pandas as pd\n",
        "\n",
        "all_train_dfs = []\n",
        "all_test_dfs = []\n",
        "datasets_par_index = {}\n",
        "\n",
        "for i in range(4):\n",
        "    print(f\"Traitement de l'index {i}...\")\n",
        "\n",
        "    # 1. R√©cup√©ration\n",
        "    X_train_raw = data_store[f'kaggle_source_cate_{i}_train.npy']\n",
        "    y_train_raw = data_store[f'kaggle_source_cate_{i}_train_label.npy']\n",
        "    X_test_raw  = data_store[f'kaggle_source_cate_{i}_test.npy']\n",
        "    y_test_raw  = data_store[f'kaggle_source_cate_{i}_test_label.npy']\n",
        "\n",
        "    # 2. Conversion dynamique\n",
        "    df_X_train = pd.DataFrame(X_train_raw).add_prefix('feat_')\n",
        "    df_X_test  = pd.DataFrame(X_test_raw).add_prefix('feat_')\n",
        "\n",
        "    # On cr√©e les noms de colonnes dynamiquement pour les labels (label_0, label_1, etc.)\n",
        "    col_labels = [f'label_{j}' for j in range(y_train_raw.shape[1])]\n",
        "    df_y_train = pd.DataFrame(y_train_raw, columns=col_labels)\n",
        "    df_y_test  = pd.DataFrame(y_test_raw, columns=col_labels)\n",
        "\n",
        "    # 3. Concat√©nation horizontale\n",
        "    df_train_full = pd.concat([df_X_train, df_y_train], axis=1)\n",
        "    df_test_full  = pd.concat([df_X_test, df_y_test], axis=1)\n",
        "\n",
        "    # Identification de la source\n",
        "    df_train_full['source_index'] = i\n",
        "    df_test_full['source_index'] = i\n",
        "\n",
        "    datasets_par_index[i] = {'train': df_train_full, 'test': df_test_full}\n",
        "    all_train_dfs.append(df_train_full)\n",
        "    all_test_dfs.append(df_test_full)\n",
        "\n",
        "# 4. Fusion finale\n",
        "df_final_train = pd.concat(all_train_dfs, ignore_index=True)\n",
        "df_final_test  = pd.concat(all_test_dfs, ignore_index=True)\n",
        "\n",
        "print(f\"\\nTermin√© ! Colonnes cr√©√©es pour les labels : {col_labels}\")\n",
        "print(f\"Format final du train : {df_final_train.shape}\")\n",
        "print(f\"Format final du train : {df_final_test.shape}\")\n",
        "print(df_final_train.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "HsaWLCLaPcIE",
        "outputId": "9ad21cd8-9916-4c7f-e884-02d360304b26"
      },
      "outputs": [],
      "source": [
        "# Affichage des 5 premi√®res lignes des labels pour l'index 0\n",
        "print(\"Aper√ßu des labels (index 0) :\")\n",
        "display(datasets_par_index[0]['train'][[f'label_{j}' for j in range(y_train_raw.shape[1])]].head())\n",
        "\n",
        "# V√©rification des valeurs uniques pour voir si c'est du binaire (0/1)\n",
        "print(\"\\nValeurs uniques par colonne de label :\")\n",
        "for col in [f'label_{j}' for j in range(y_train_raw.shape[1])]:\n",
        "    unique_vals = datasets_par_index[0]['train'][col].unique()\n",
        "    print(f\"{col} : {unique_vals}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpMCOO5oR652"
      },
      "source": [
        "la colonne \"label_1\" servira de cible (1=fraude, 0= non fraude)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "249AV6Z4W2Xw",
        "outputId": "bc5953e1-f43a-459b-e38f-7521e6ef8cd2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Calcul des proportions\n",
        "counts = df_final_train['label_1'].value_counts()\n",
        "proportions = df_final_train['label_1'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"--- R√©partition des classes ---\")\n",
        "for val, count in counts.items():\n",
        "    print(f\"Classe {val} : {count} individus ({proportions[val]:.2f}%)\")\n",
        "\n",
        "# 2. Cr√©ation du graphique\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=counts.index, y=counts.values, palette='viridis')\n",
        "\n",
        "plt.title('R√©partition des classes (0 vs 1) dans le dataset')\n",
        "plt.xlabel('Classe (Target)')\n",
        "plt.ylabel('Nombre de lignes')\n",
        "plt.xticks(ticks=[0, 1], labels=['Classe 0', 'Classe 1'])\n",
        "\n",
        "# Ajout des pourcentages au-dessus des barres\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count + (max(counts)*0.01), f'{proportions[i]:.1f}%', ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "CdA8kl1x0erf",
        "outputId": "0ab5fca8-8724-4b9e-a463-c2d51eb12454"
      },
      "outputs": [],
      "source": [
        "# 1. Calcul des proportions\n",
        "counts = df_final_test['label_1'].value_counts()\n",
        "proportions = df_final_test['label_1'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"--- R√©partition des classes ---\")\n",
        "for val, count in counts.items():\n",
        "    print(f\"Classe {val} : {count} individus ({proportions[val]:.2f}%)\")\n",
        "\n",
        "# 2. Cr√©ation du graphique\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=counts.index, y=counts.values, palette='viridis')\n",
        "\n",
        "plt.title('R√©partition des classes (0 vs 1) dans le dataset')\n",
        "plt.xlabel('Classe (Target)')\n",
        "plt.ylabel('Nombre de lignes')\n",
        "plt.xticks(ticks=[0, 1], labels=['Classe 0', 'Classe 1'])\n",
        "\n",
        "# Ajout des pourcentages au-dessus des barres\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count + (max(counts)*0.01), f'{proportions[i]:.1f}%', ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvtOyLxRbR_Z",
        "outputId": "c0e39d39-106e-4ae6-ac81-8ad4d0527e54"
      },
      "outputs": [],
      "source": [
        "#v√©rification des variables si certaines sont des constantes\n",
        "# 1. Identifier les colonnes 'feat_'\n",
        "feat_cols = [c for c in df_final_train.columns if c.startswith('feat_')]\n",
        "\n",
        "# 2. V√©rifier le nombre de valeurs uniques par colonne\n",
        "# nunique() renvoie 1 si toutes les valeurs de la colonne sont identiques\n",
        "constant_features = [col for col in feat_cols if df_final_train[col].nunique() <= 1]\n",
        "\n",
        "# 3. Affichage des r√©sultats\n",
        "print(f\"Nombre total de descripteurs analys√©s : {len(feat_cols)}\")\n",
        "print(f\"Nombre de descripteurs constants trouv√©s : {len(constant_features)}\")\n",
        "\n",
        "if len(constant_features) > 0:\n",
        "    print(\"\\nListe des descripteurs constants :\")\n",
        "    print(constant_features)\n",
        "\n",
        "    # Optionnel : Supprimer ces colonnes des datasets\n",
        "    # df_final_train.drop(columns=constant_features, inplace=True)\n",
        "    # df_final_test.drop(columns=constant_features, inplace=True)\n",
        "    # print(\"\\nColonnes constantes supprim√©es des DataFrames.\")\n",
        "else:\n",
        "    print(\"\\nAucun descripteur constant d√©tect√©. Tous les 'feat_' varient !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8XEXapjzbb6a",
        "outputId": "65d6c168-a556-49c8-9c12-53db8f286b3e"
      },
      "outputs": [],
      "source": [
        "# 1. Calcul de la corr√©lation entre toutes les colonnes et la cible\n",
        "# On se concentre uniquement sur la colonne 'target' (anciennement label_1)\n",
        "correlations = df_final_train.corr()['label_1'].sort_values(ascending=False)\n",
        "\n",
        "# 2. S√©paration des corr√©lations positives et n√©gatives fortes\n",
        "# On exclut la cible elle-m√™me (qui a une corr√©lation de 1.0)\n",
        "top_positives = correlations[correlations < 1.0].head(15)\n",
        "top_negatives = correlations.tail(15)\n",
        "\n",
        "print(\"--- Top 10 des corr√©lations positives (li√©es au '1') ---\")\n",
        "print(top_positives)\n",
        "\n",
        "print(\"\\n--- Top 10 des corr√©lations n√©gatives (li√©es au '0') ---\")\n",
        "print(top_negatives)\n",
        "\n",
        "# 3. Visualisation des corr√©lations les plus importantes\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_corr_features = pd.concat([top_positives, top_negatives])\n",
        "sns.barplot(x=top_corr_features.values, y=top_corr_features.index, palette='coolwarm')\n",
        "plt.title('Descripteurs les plus corr√©l√©s √† la cible (Target)')\n",
        "plt.xlabel('Coefficient de Corr√©lation')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "An0_0iq2qJDm",
        "outputId": "8ce83eb0-51ed-4af1-de49-0ffbd8f672ab"
      },
      "outputs": [],
      "source": [
        "# 1. S√©lection des colonnes les plus pertinentes pour √©viter de surcharger la heatmap\n",
        "# On prend les 15 descripteurs les plus corr√©l√©s √† la cible (en valeur absolue)\n",
        "target_corr = df_final_train.corr()['label_1'].abs().sort_values(ascending=False)\n",
        "top_features = target_corr.iloc[1:16].index.tolist() # On exclut la target elle-m√™me\n",
        "\n",
        "# 2. Calcul de la matrice de corr√©lation pour ces colonnes + la target\n",
        "corr_matrix = df_final_train[top_features + ['label_1']].corr()\n",
        "\n",
        "# 3. Affichage de la table (Matrice)\n",
        "print(\"Extrait de la matrice de corr√©lation (Top 15 features) :\")\n",
        "display(corr_matrix)\n",
        "\n",
        "# 4. G√©n√©ration de la Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Masque pour ne pas afficher la moiti√© sup√©rieure (doublon sym√©trique)\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "sns.heatmap(corr_matrix,\n",
        "            mask=mask,\n",
        "            annot=True,          # Affiche les valeurs\n",
        "            fmt=\".2f\",           # 2 d√©cimales\n",
        "            cmap='coolwarm',     # Bleu (n√©gatif) √† Rouge (positif)\n",
        "            center=0,\n",
        "            linewidths=.5,\n",
        "            cbar_kws={\"shrink\": .8})\n",
        "\n",
        "plt.title('Heatmap des corr√©lations (Top 15 features + Target)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDflTYUG2ruu",
        "outputId": "54f3b3f0-2794-4237-9269-2f2ea145229d"
      },
      "outputs": [],
      "source": [
        "#identification de variables redondantes\n",
        "# 1. Calcul de la matrice de corr√©lation absolue\n",
        "# On utilise la valeur absolue car une corr√©lation de -0.95 est aussi redondante que 0.95\n",
        "corr_matrix = df_final_train.corr().abs()\n",
        "\n",
        "# 2. S√©lectionner la partie sup√©rieure de la matrice pour √©viter les doublons (A-B et B-A)\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# 3. Trouver les colonnes avec une corr√©lation sup√©rieure au seuil de 0.90\n",
        "threshold = 0.90\n",
        "redundant_pairs = [\n",
        "    (column, row, upper.loc[row, column])\n",
        "    for column in upper.columns\n",
        "    for row in upper.index\n",
        "    if upper.loc[row, column] > threshold\n",
        "]\n",
        "\n",
        "# 4. Affichage des r√©sultats\n",
        "print(f\"--- Recherche des variables redondantes (Seuil > {threshold}) ---\")\n",
        "if not redundant_pairs:\n",
        "    print(\"Aucune paire de variables fortement corr√©l√©es n'a √©t√© trouv√©e.\")\n",
        "else:\n",
        "    print(f\"Nombre de paires trouv√©es : {len(redundant_pairs)}\\n\")\n",
        "    for var1, var2, val in redundant_pairs:\n",
        "        print(f\"üî¥ {var1} et {var2} sont corr√©l√©es √† {val:.4f}\")\n",
        "\n",
        "# 5. Optionnel : Lister les colonnes √† supprimer\n",
        "# On choisit de supprimer la deuxi√®me variable de chaque paire pour nettoyer le dataset\n",
        "to_drop = [pair[0] for pair in redundant_pairs]\n",
        "to_drop = list(set(to_drop)) # Supprimer les doublons dans la liste de suppression\n",
        "\n",
        "print(f\"\\nSuggestion de colonnes √† supprimer ({len(to_drop)}) : {to_drop}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyhXSqxCbcnE"
      },
      "outputs": [],
      "source": [
        "#d√©finition des ensembles X_train, X_test, y_train et y_test\n",
        "X_train= df_X_train\n",
        "X_test=df_X_test\n",
        "y_train=df_y_train['label_1']\n",
        "y_test=df_y_test['label_1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLfYqAVmc_f9",
        "outputId": "af4b038c-1346-4f1d-f257-a09c1e32ebcb"
      },
      "outputs": [],
      "source": [
        "#test R√©gression Logistique\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "# 1. Configuration du protocole de validation\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 2. D√©finition du mod√®le de base\n",
        "# Note : On utilise le solver 'liblinear' car il supporte √† la fois 'l1' et 'l2'\n",
        "lr_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# 3. Grille d'hyperparam√®tres\n",
        "param_grid = {\n",
        "    'C': np.logspace(-3, 2, 10),\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# 4. Initialisation de la recherche par grille (GridSearch)\n",
        "# Optimisation bas√©e sur le score F1\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=lr_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv_strategy,\n",
        "    scoring='f1',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 5. Entra√Ænement sur X_train et y_train\n",
        "print(\"D√©but de l'optimisation des hyperparam√®tres...\")\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 6. R√©sultats et √©valuation\n",
        "print(f\"\\nMeilleurs hyperparam√®tres : {grid_search.best_params_}\")\n",
        "print(f\"Meilleur score F1 en validation crois√©e : {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Pr√©diction sur l'ensemble de test\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Rapport de performance sur l'ensemble Test ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ===============================\n",
        "# √âvaluation finale\n",
        "# ===============================\n",
        "\n",
        "# R√©cup√©ration du meilleur mod√®le\n",
        "best_lr = grid_search.best_estimator_\n",
        "\n",
        "# Pr√©dictions finales sur le jeu de test\n",
        "y_pred_lr = best_lr.predict(X_test)\n",
        "\n",
        "# M√©triques\n",
        "precision_lr = precision_score(y_test, y_pred_lr, pos_label=1)\n",
        "recall_lr    = recall_score(y_test, y_pred_lr, pos_label=1)\n",
        "f1_lr        = f1_score(y_test, y_pred_lr, pos_label=1)\n",
        "\n",
        "print(\"\\n--- M√©triques finales ---\")\n",
        "print(f\"Precision (fraude): {precision_lr:.3f}\")\n",
        "print(f\"Recall    (fraude): {recall_lr:.3f}\")\n",
        "print(f\"F1-score  (fraude): {f1_lr:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J09X91GmeYpb",
        "outputId": "2a3d02aa-92b5-407d-8e36-f22be9e07b7c"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "# Configuration\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 500],\n",
        "    'max_depth': [10, 30, None]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid_rf,\n",
        "    cv=cv,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train.values.ravel())\n",
        "print(f\"RF - Meilleurs param√®tres: {grid_rf.best_params_}\")\n",
        "print(f\"RF - Score F1 Test: {grid_rf.score(X_test, y_test):.4f}\")\n",
        "# Pr√©diction sur l'ensemble de test\n",
        "y_pred = grid_rf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ===============================\n",
        "# Random Forest - √âvaluation finale\n",
        "# ===============================\n",
        "\n",
        "# Meilleur mod√®le RF\n",
        "best_rf = grid_rf.best_estimator_\n",
        "\n",
        "# Pr√©dictions finales sur le jeu de test\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# M√©triques\n",
        "precision_rf = precision_score(y_test, y_pred_rf, pos_label=1)\n",
        "recall_rf    = recall_score(y_test, y_pred_rf, pos_label=1)\n",
        "f1_rf        = f1_score(y_test, y_pred_rf, pos_label=1)\n",
        "\n",
        "print(\"\\n--- M√©triques finales ---\")\n",
        "print(f\"Precision (fraude): {precision_rf:.3f}\")\n",
        "print(f\"Recall    (fraude): {recall_rf:.3f}\")\n",
        "print(f\"F1-score  (fraude): {f1_rf:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhWvkiUPHrCy",
        "outputId": "ebaf9754-8d02-499d-a3f9-5fbb4e022fa1"
      },
      "outputs": [],
      "source": [
        "# Version raffin√©e de Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Protocole de validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 2. Grille affin√©e (Fine-tuning)\n",
        "# On explore autour des limites pr√©c√©demment atteintes\n",
        "param_grid_refined = {\n",
        "    'n_estimators': [500, 600, 700],        # Exploration au-del√† de 500\n",
        "    'max_depth': [30, 40, 50, None],        # Pr√©cision autour de la profondeur √©lev√©e\n",
        "    'min_samples_split': [2, 5, 10],        # \"Pas autour de z√©ro\" pour la division des n≈ìuds\n",
        "}\n",
        "\n",
        "# 3. Initialisation\n",
        "grid_rf_refined = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid_refined,\n",
        "    cv=cv,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# 4. Entra√Ænement\n",
        "print(\"Lancement du GridSearch affin√© pour Random Forest...\")\n",
        "grid_rf_refined.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 5. R√©sultats\n",
        "print(f\"\\nMeilleurs param√®tres affin√©s : {grid_rf_refined.best_params_}\")\n",
        "print(f\"Meilleur score F1 (Validation) : {grid_rf_refined.best_score_:.4f}\")\n",
        "\n",
        "# Score sur le Test Set\n",
        "final_score = grid_rf_refined.score(X_test, y_test)\n",
        "print(f\"Score F1 final sur Test : {final_score:.4f}\")\n",
        "\n",
        "# Pr√©diction sur l'ensemble de test\n",
        "y_pred = grid_rf_refined.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ===============================\n",
        "# Random Forest (raffin√©e)\n",
        "# ===============================\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Meilleur mod√®le RF raffin√©\n",
        "best_rf_refined = grid_rf_refined.best_estimator_\n",
        "\n",
        "# Pr√©dictions finales sur le jeu de test\n",
        "y_pred_rf_refined = best_rf_refined.predict(X_test)\n",
        "\n",
        "# M√©triques\n",
        "precision_rf_refined = precision_score(y_test, y_pred_rf_refined, pos_label=1)\n",
        "recall_rf_refined    = recall_score(y_test, y_pred_rf_refined, pos_label=1)\n",
        "f1_rf_refined        = f1_score(y_test, y_pred_rf_refined, pos_label=1)\n",
        "\n",
        "print(\"\\n--- M√©triques finales ---\")\n",
        "print(f\"Precision (fraude): {precision_rf_refined:.3f}\")\n",
        "print(f\"Recall    (fraude): {recall_rf_refined:.3f}\")\n",
        "print(f\"F1-score  (fraude): {f1_rf_refined:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9eVmNBVfbwT",
        "outputId": "55f35b10-f9a5-4cd7-b745-bd5c465a94a6"
      },
      "outputs": [],
      "source": [
        "#XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 6, 9]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(\n",
        "    XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
        "    param_grid=param_grid_xgb,\n",
        "    cv = cv,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_xgb.fit(X_train, y_train.values.ravel())\n",
        "print(f\"XGB - Meilleurs param√®tres: {grid_xgb.best_params_}\")\n",
        "print(f\"XGB - Score F1 Test: {grid_xgb.score(X_test, y_test):.4f}\")\n",
        "# Pr√©diction sur l'ensemble de test\n",
        "y_pred = grid_xgb.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ===============================\n",
        "# XGBoost - √âvaluation finale \n",
        "# ===============================\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Meilleur mod√®le XGB\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "\n",
        "# Pr√©dictions finales sur le jeu de test (seuil par d√©faut = 0.5)\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "\n",
        "# M√©triques (classe positive = fraude = 1)\n",
        "precision_xgb = precision_score(y_test, y_pred_xgb, pos_label=1)\n",
        "recall_xgb    = recall_score(y_test, y_pred_xgb, pos_label=1)\n",
        "f1_xgb        = f1_score(y_test, y_pred_xgb, pos_label=1)\n",
        "\n",
        "print(\"\\n--- M√©triques finales ---\")\n",
        "print(f\"Precision (fraude): {precision_xgb:.3f}\")\n",
        "print(f\"Recall    (fraude): {recall_xgb:.3f}\")\n",
        "print(f\"F1-score  (fraude): {f1_xgb:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GoTjfFhIfm-a",
        "outputId": "130f4d3b-0a78-49ba-9803-2f7b906879fa"
      },
      "outputs": [],
      "source": [
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(\n",
        "    SVC(random_state=42),\n",
        "    param_grid=param_grid_svm,\n",
        "    cv=cv,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train, y_train.values.ravel())\n",
        "print(f\"SVM - Meilleurs param√®tres: {grid_svm.best_params_}\")\n",
        "print(f\"SVM - Score F1 Test: {grid_svm.score(X_test, y_test):.4f}\")\n",
        "# Pr√©diction sur l'ensemble de test\n",
        "y_pred = grid_svm.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ===============================\n",
        "# SVM - √âvaluation finale\n",
        "# ===============================\n",
        "\n",
        "# Meilleur mod√®le SVM\n",
        "best_svm = grid_svm.best_estimator_\n",
        "\n",
        "# Pr√©dictions finales sur le jeu de test\n",
        "y_pred_svm = best_svm.predict(X_test)\n",
        "\n",
        "# M√©triques (classe positive = fraude = 1)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, pos_label=1)\n",
        "recall_svm    = recall_score(y_test, y_pred_svm, pos_label=1)\n",
        "f1_svm        = f1_score(y_test, y_pred_svm, pos_label=1)\n",
        "\n",
        "print(\"\\n--- M√©triques finales ---\")\n",
        "print(f\"Precision (fraude): {precision_svm:.3f}\")\n",
        "print(f\"Recall    (fraude): {recall_svm:.3f}\")\n",
        "print(f\"F1-score  (fraude): {f1_svm:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg9rQTirrOGw"
      },
      "outputs": [],
      "source": [
        "# Pr√©diction sur l'ensemble de test\n",
        "SVC_model=svc_model = SVC(C=10, kernel='linear')\n",
        "SVC_model_fit=svc_model.fit(X_train, y_train)\n",
        "y_pred = SVC_model_fit(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggg4dj_zfyVI",
        "outputId": "9071974d-eb69-40e4-b202-591f54b4124c"
      },
      "outputs": [],
      "source": [
        "#KNN\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "# 1. D√©finition du pipeline : Mise √† l'√©chelle puis Classifieur\n",
        "# Le pipeline traite les donn√©es dans l'ordre pour chaque pli de la validation crois√©e\n",
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# 2. Configuration du protocole de validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 3. Grille d'hyperparam√®tres\n",
        "param_grid_knn = {\n",
        "    'knn__n_neighbors': [3, 5, 7, 11],\n",
        "    'knn__weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "# 4. Initialisation de la recherche par grille\n",
        "grid_knn = GridSearchCV(\n",
        "    knn_pipeline,\n",
        "    param_grid=param_grid_knn,\n",
        "    cv=cv,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Entra√Ænement\n",
        "print(\"Entra√Ænement du k-NN avec StandardScaler...\")\n",
        "grid_knn.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 6. R√©sultats\n",
        "print(f\"\\nMeilleurs param√®tres : {grid_knn.best_params_}\")\n",
        "print(f\"Meilleur score F1 (Validation CV) : {grid_knn.best_score_:.4f}\")\n",
        "\n",
        "# √âvaluation finale sur l'ensemble Test\n",
        "test_score = grid_knn.score(X_test, y_test)\n",
        "print(f\"Score F1 sur l'ensemble Test : {test_score:.4f}\")\n",
        "\n",
        "# Pr√©diction sur l'ensemble de test\n",
        "y_pred = grid_knn.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ===============================\n",
        "# k-NN - √âvaluation finale\n",
        "# ===============================\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Meilleur mod√®le k-NN\n",
        "best_knn = grid_knn.best_estimator_\n",
        "\n",
        "# Pr√©dictions finales sur le jeu de test\n",
        "y_pred_knn = best_knn.predict(X_test)\n",
        "\n",
        "# M√©triques centr√©es sur la classe fraude (1)\n",
        "precision_knn = precision_score(y_test, y_pred_knn, pos_label=1)\n",
        "recall_knn    = recall_score(y_test, y_pred_knn, pos_label=1)\n",
        "f1_knn        = f1_score(y_test, y_pred_knn, pos_label=1)\n",
        "\n",
        "print(\"\\n--- M√©triques finales ---\")\n",
        "print(f\"Precision (fraude): {precision_knn:.3f}\")\n",
        "print(f\"Recall    (fraude): {recall_knn:.3f}\")\n",
        "print(f\"F1-score  (fraude): {f1_knn:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfRN5zN3gDck",
        "outputId": "5b71d6d9-0392-4134-81e4-12c0e05bfad5"
      },
      "outputs": [],
      "source": [
        "#Application de la m√©thode de sous-√©chantillonnage\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Application du sous-√©chantillonnage\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# 2. Entra√Ænement du mod√®le\n",
        "model_under = XGBClassifier(learning_rate=0.1, max_depth=9, random_state=42)\n",
        "model_under.fit(X_resampled, y_resampled)\n",
        "\n",
        "# 3. √âvaluation\n",
        "y_pred = model_under.predict(X_test)\n",
        "print(\"--- R√©sultats Under-sampling ---\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRG4MRKG16NS",
        "outputId": "552deb0f-31b5-4932-ddb3-b7f0ca52ecc2"
      },
      "outputs": [],
      "source": [
        "#Application de SMOTE\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# 1. G√©n√©ration de donn√©es synth√©tiques\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# 2. Entra√Ænement du mod√®le\n",
        "model_smote = XGBClassifier(learning_rate=0.1, max_depth=9, random_state=42)\n",
        "model_smote.fit(X_resampled, y_resampled)\n",
        "\n",
        "# 3. √âvaluation\n",
        "y_pred = model_smote.predict(X_test)\n",
        "print(\"--- R√©sultats SMOTE ---\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwNmNRzV2D1S",
        "outputId": "90a052d2-7a4f-45a7-b051-886dae0f4176"
      },
      "outputs": [],
      "source": [
        "#Application Class-Weighting\n",
        "\n",
        "\n",
        "# 1. Calcul du poids (ratio class 0 / class 1)\n",
        "counter = np.bincount(y_train)\n",
        "ratio = counter[0] / counter[1]\n",
        "\n",
        "# 2. Entra√Ænement avec pond√©ration\n",
        "model_weighted = XGBClassifier(\n",
        "    learning_rate=0.1,\n",
        "    max_depth=9,\n",
        "    scale_pos_weight=ratio, # Applique le poids ici\n",
        "    random_state=42\n",
        ")\n",
        "model_weighted.fit(X_train, y_train)\n",
        "\n",
        "# 3. √âvaluation\n",
        "y_pred = model_weighted.predict(X_test)\n",
        "print(\"--- R√©sultats Class-Weighting ---\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fraudapt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
